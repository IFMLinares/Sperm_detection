# **üß¨ Detecci√≥n de Espermatozoides con IA (Fase 1: Detecci√≥n)**

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![YOLOv8](https://img.shields.io/badge/Ultralytics-YOLOv8-3776AB)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

Este proyecto implementa un sistema de Visi√≥n Artificial basado en los est√°ndares del **Manual de la OMS (2021)** para el an√°lisis de semen.

**Objetivo de la Fase 1:** Detectar y recortar autom√°ticamente espermatozoides individuales en im√°genes de microscop√≠a (100x) utilizando **YOLOv8** y aceleraci√≥n por GPU (NVIDIA RTX 3080).

## **üìã 1\. Requisitos Previos**

Antes de comenzar, aseg√∫rate de tener instalado:

1. **Miniconda** (Gestor de entornos Python).  
2. **Visual Studio Code** (Editor de c√≥digo).  
3. **Drivers de NVIDIA** actualizados (para soporte CUDA).  
4. **Hardware Recomendado:** GPU NVIDIA con al menos 4GB de VRAM (Probado en RTX 3080 10GB).

## **‚öôÔ∏è 2\. Configuraci√≥n Inicial del Sistema (Solo primera vez)**

Si es la primera vez que usas Conda en Windows con VS Code, debes realizar estos ajustes cr√≠ticos para evitar errores de permisos, rutas y licencias.

### **A. Agregar Conda al PATH de Windows**

Si la terminal no reconoce el comando conda, debes agregarlo manualmente a las variables de entorno:

1. Busca en Windows **"Editar las variables de entorno de esta cuenta"**.  
2. Edita la variable Path y agrega estas 3 rutas (cambia TU\_USUARIO por tu nombre de usuario real):  
   * C:\\Users\\TU\_USUARIO\\miniconda3  
   * C:\\Users\\TU\_USUARIO\\miniconda3\\Scripts  
   * C:\\Users\\TU\_USUARIO\\miniconda3\\Library\\bin  
3. **Reinicia** Visual Studio Code para aplicar los cambios.

### **B. Inicializar PowerShell y Permisos**

Abre una terminal en VS Code (Ctrl \+ √±) y ejecuta estos comandos uno por uno para permitir la ejecuci√≥n de scripts y vincular Conda:

\# 1\. Permitir scripts (Soluciona error rojo de seguridad "UnauthorizedAccess")  
Set-ExecutionPolicy RemoteSigned \-Scope CurrentUser

\# 2\. Inicializar Conda en PowerShell  
conda init powershell

*‚ö†Ô∏è **IMPORTANTE:** Cierra la terminal actual (icono de basura üóëÔ∏è) y abre una nueva para aplicar estos cambios.*

### **C. Aceptar T√©rminos de Servicio (Soluci√≥n a error 'CondaToSNonInteractiveError')**

Anaconda requiere aceptar expl√≠citamente las licencias de sus canales. Ejecuta estos comandos si recibes errores al crear el entorno:

conda tos accept \--override-channels \--channel \[https://repo.anaconda.com/pkgs/main\](https://repo.anaconda.com/pkgs/main)  
conda tos accept \--override-channels \--channel \[https://repo.anaconda.com/pkgs/r\](https://repo.anaconda.com/pkgs/r)  
conda tos accept \--override-channels \--channel \[https://repo.anaconda.com/pkgs/msys2\](https://repo.anaconda.com/pkgs/msys2)

## **üöÄ 3\. Creaci√≥n del Entorno Virtual**

Sigue estos pasos para crear el entorno aislado y cargar las librer√≠as de Inteligencia Artificial:

\# 1\. Crear el entorno (Python 3.10 es la versi√≥n m√°s estable para YOLOv8)  
conda create \-n tesis\_espermas python=3.10 \-y

\# 2\. Activar el entorno  
conda activate tesis\_espermas  
\# (IMPORTANTE: Debes ver '(tesis\_espermas)' en verde a la izquierda de tu terminal)

\# 3\. Instalar librer√≠as principales  
pip install ultralytics roboflow

## **üì• 4\. Descarga del Dataset (Script existente)**

Usa el script ya incluido [download_data.py](download_data.py) para descargar autom√°ticamente el dataset etiquetado desde Roboflow Universe y organizarlo en formato YOLOv8.

- El script requiere tu API Key privada de Roboflow. Evita publicar esa clave en GitHub.
- Si cambiaste credenciales, edita temporalmente el archivo y considera mover la clave a una variable de entorno.

**Ejecutar descarga:**

```
python download_data.py
```

**Nota de seguridad:** No subas tu API Key al repositorio p√∫blico. En producci√≥n, usa variables de entorno (`set ROBOFLOW_API_KEY=...`) y lee `os.getenv` en el script.

## **üß† 5\. Entrenamiento del Modelo (Script existente)**

Usa el script [train_hunter.py](train_hunter.py) para el Fine-Tuning con **Ultralytics YOLOv8**. El script detecta autom√°ticamente `data.yaml`, elige GPU si est√° disponible y guarda el mejor modelo en `runs/detect/trained_sperm_model/weights/best.pt`.

**Iniciar entrenamiento:**

```
python train_hunter.py
```

**Modelos base disponibles:**
- [yolov8s.pt](yolov8s.pt): equilibrado para objetos peque√±os (recomendado).
- [yolo11n.pt](yolo11n.pt): versi√≥n ligera de YOLOv11 (r√°pida, menos precisa).

Si tu GPU se queda sin memoria, reduce `batch` (el script ya ajusta CPU/GPU).

---

## **üîé 6\. Fase 1: Detecci√≥n y Organizaci√≥n de Resultados**

Una vez entrenado, ejecuta la fase de detecci√≥n y recorte. Tienes dos opciones complementarias:

**A) Recorte autom√°tico y guardado de crops**
- Script: [detect_crop.py](detect_crop.py)
- Genera im√°genes con bounding boxes y recortes individuales por clase.

```
python detect_crop.py
```

Salida:
- Im√°genes anotadas: `runs/detect/result_fase_1/`
- Recortes: `runs/detect/result_fase_1/crops/sperm/`

**B) Organizaci√≥n por imagen con mapa numerado**
- Script: [detect_organize.py](detect_organize.py)
- Crea una carpeta por imagen en [result_fase_1](result_fase_1) y guarda:
  - Recortes numerados `*_esperma_{ID}.jpg`
  - Un ‚ÄúMAPA_NUMERADO‚Äù con rect√°ngulos y etiquetas `ID`.

```
python detect_organize.py
```

Ajusta `CONFIANZA`, `CARPETA_ORIGEN` y rutas en cada script si lo necesitas.

---

## **üõ°Ô∏è 7\. Seguridad y Buenas Pr√°cticas**

- **API Keys:** No publiques credenciales. Usa variables de entorno o `.env`.
- **Pesos del modelo:** Verifica licencias si subes `*.pt` a GitHub.
- **Datos sensibles:** Anonimiza im√°genes si son cl√≠nicas.

**Configurar `.env` (recomendado):**
- Copia [\.env.example](.env.example) a `.env` y rellena `ROBOFLOW_API_KEY`.
- En Windows tambi√©n puedes definirla de forma persistente:

```
setx ROBOFLOW_API_KEY TU_API_KEY
```

El script [download_data.py](download_data.py) lee `ROBOFLOW_API_KEY` desde el entorno o `.env`.

---

## **üó∫Ô∏è 8\. Roadmap Fase 2 (Clasificaci√≥n/Morfolog√≠a)**

- Conteo robusto y m√©tricas por campo (confiables para reporte).
- Clasificaci√≥n de morfolog√≠a normal/anormal y motilidad.
- Post-procesamiento y exportaci√≥n (CSV/JSON) por muestra.
- Panel simple de visualizaci√≥n y QA de anotaciones.

---

## **üì§ 9\. Publicaci√≥n en GitHub: qu√© subir y qu√© excluir**

- **Licencia:**
  - **MIT**: muy simple y permisiva; ideal si quieres facilitar uso y reutilizaci√≥n sin condiciones complejas.
  - **Apache-2.0**: tambi√©n permisiva, con cl√°usula expl√≠cita de patentes y t√©rminos m√°s detallados; √∫til si te interesa cobertura legal adicional.
  - Elige MIT por simplicidad; Apache si te importa la protecci√≥n/claridad de patentes.

- **Secretos:** no subas credenciales. Usa `.env` (ejemplo en [\.env.example](.env.example)).

- **Datos locales (im√°genes originales):**
  - Si son sensibles (cl√≠nicos), **no publiques**. Considera subir solo **un peque√±o subconjunto anonimizado** o recortado.
  - Para datasets grandes, usa **Git LFS** o enlaces externos (Roboflow, Kaggle, Drive) y documenta c√≥mo obtenerlos.

- **Resultados (crops, mapas numerados):**
  - No es necesario subir todo; incluye **unos pocos ejemplos** en `documentation/` o como im√°genes en el README.
  - El resto queda excluido por [\.gitignore](.gitignore): `result_fase_1/` y `runs/`.

- **Pesos del modelo (`*.pt`):**
  - Tus pesos entrenados pueden ser grandes; comp√°rtelos como **release assets**, en **Hugging Face**, **Drive**, o con **Git LFS**.
  - Verifica licencias del modelo base y dataset antes de distribuir pesos.

El repositorio ya incluye [\.gitignore](.gitignore) para excluir `.env`, `my_images/`, `result_fase_1/`, `runs/`.

## **üõ†Ô∏è Soluci√≥n de Errores Comunes**

| Error | Causa Probable | Soluci√≥n |
| :---- | :---- | :---- |
| conda: The term is not recognized | Falta PATH en Windows | Ver Secci√≥n 2.A de este documento. |
| UnauthorizedAccess / scripts disabled | PowerShell bloqueado | Ver Secci√≥n 2.B (Comando Set-ExecutionPolicy). |
| CUDA Out of Memory | La memoria de la GPU se llen√≥ | Baja el batch=24 a batch=16 o 8 en el archivo entrenar.py. |
| Environment not found | No creaste el entorno | Ejecuta conda create... nuevamente. |
| CondaToSNonInteractiveError | Licencias no aceptadas | Ver Secci√≥n 2.C. |

## **üìÇ Estructura del Proyecto**

Una vez ejecutados los scripts, tu carpeta deber√≠a verse as√≠:

DetectorEspermas/  
‚îÇ  
‚îú‚îÄ‚îÄ README.md            \# Este archivo de documentaci√≥n  
‚îú‚îÄ‚îÄ descargar\_data.py    \# Script de descarga  
‚îú‚îÄ‚îÄ entrenar.py          \# Script de entrenamiento  
‚îú‚îÄ‚îÄ Sperm-detection.../  \# Carpeta generada por Roboflow (puede variar nombre)  
‚îÇ   ‚îú‚îÄ‚îÄ train/           \# Im√°genes de entrenamiento  
‚îÇ   ‚îú‚îÄ‚îÄ valid/           \# Im√°genes de validaci√≥n  
‚îÇ   ‚îî‚îÄ‚îÄ data.yaml        \# Configuraci√≥n del dataset  
‚îÇ  
‚îî‚îÄ‚îÄ runs/                \# RESULTADOS DEL ENTRENAMIENTO  
    ‚îî‚îÄ‚îÄ detect/  
        ‚îî‚îÄ‚îÄ cazador\_espermas\_v1/  
            ‚îî‚îÄ‚îÄ weights/  
                ‚îú‚îÄ‚îÄ best.pt  \<-- TU MODELO FINAL (USAR ESTE PARA DETECTAR)  
                ‚îî‚îÄ‚îÄ last.pt  
